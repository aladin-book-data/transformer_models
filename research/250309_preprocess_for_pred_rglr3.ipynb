{"cells":[{"cell_type":"markdown","metadata":{"id":"hMv-mcfb1cxL"},"source":["## 요약\n","- 기존 전처리 코드에서는 정수 인코딩한 token들도 scaling을 진행함\n","- transformer에서 embedding model을 사용하려면 정수 값으로 입력 받아야 함\n","- 또한 중고 도서 데이터가 아닌 도서 정보만 사용\n","- 이에 맞게 코드 수정"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6Rd3woP61cxV"},"outputs":[],"source":["import os, natsort, re\n","from tqdm import tqdm\n","import time, random"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Jdm14GU9JE1n"},"outputs":[],"source":["from itertools import repeat, chain\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_absolute_percentage_error as mape\n","from sklearn.metrics import mean_squared_error as mse\n","from sklearn.metrics import mean_squared_log_error as msle\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats(\"png2x\")\n","# 테마 설정: \"default\", \"classic\", \"dark_background\", \"fivethirtyeight\", \"seaborn\"\n","mpl.style.use(\"fivethirtyeight\")\n","# 이미지가 레이아웃 안으로 들어오도록 함\n","mpl.rcParams.update({\"figure.constrained_layout.use\": True})\n","mpl.rcParams['axes.unicode_minus'] = False"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"elapsed":122677,"status":"error","timestamp":1721614229201,"user":{"displayName":"이스트캠퍼스","userId":"11631653647711445405"},"user_tz":-540},"id":"vRSxgFv_1eJE","outputId":"de14af6d-3a18-47a0-8d18-a2e8faa2b8af"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive/\u001b[39m\u001b[39m'\u001b[39m, force_remount\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"tOybaY2Uo27a"},"outputs":[],"source":["#cd /content/drive/MyDrive/AI3_prjct2_aladin/"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQwX5d0D2H8a","outputId":"975fee49-7127-4362-c443-3165e8b76dc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/WASSUP-ESTsoft-AI/project/project2/'\n","/home/doeun/code/AI/ESTSOFT2024/workspace/2.project_text/transformer_models/research\n"]}],"source":["cd /content/drive/MyDrive/WASSUP-ESTsoft-AI/project/project2/"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"fPd7uoaa1cxU"},"outputs":[],"source":["# 로컬에서\n","\n","plt.rc(\"font\", family = \"D2Coding\")\n","plt.rcParams[\"axes.unicode_minus\"] = False"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"ZFuEjgvk1cxW"},"outputs":[],"source":["PRJCT_PATH = '/home/doeun/code/AI/ESTSOFT2024/workspace/2.project_text/transformer_models/'\n","#PRJCT_PATH = '/content/drive/MyDrive/WASSUP-ESTsoft-AI/project/project2/'\n","#PRJCT_PATH = '/content/drive/MyDrive/AI3_prjct2_aladin/aladin_usedbook/'\n","save_dir = 'processed/model_input'\n","dir_path = os.path.join(PRJCT_PATH,save_dir)\n","#dir_path = './'"]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rI20x4AkwggP","outputId":"2e1482eb-d760-46a3-b32c-97cdf2f2b10b"},"outputs":[{"data":{"text/plain":["'/home/doeun/code/AI/ESTSOFT2024/workspace/2.project_text/transformer_models/processed/model_input'"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["dir_path"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"EKRTD3PdyQsc"},"outputs":[],"source":["import sys\n","sys.path.append(PRJCT_PATH)"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["RSLT_DIR = PRJCT_PATH + 'processed/'\n","\n","bookinfo_name = 'bookinfo_ver{}.pkl'.format(1.0)\n","bookinfo_path = os.path.join(RSLT_DIR,bookinfo_name)\n","\n","sys.path.append(PRJCT_PATH)\n","from module_aladin.file_io import load_pkl, save_pkl\n","from module_aladin.data_process import pd_datetime_2_datenum\n","\n","from konlpy.tag import Mecab\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import itertools\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["def set_corpus_size(freq,size_feat,mode):\n","    # 입력받은 mode와 size_feat에 따라 size 크기 결정\n","    if mode == 'uniform':\n","        cond = freq['counts']>=freq['counts'].iloc[size_feat]\n","        size = np.sum(cond)\n","    elif mode =='ths':\n","        cond = freq[freq['counts'] > size_feat]\n","        size = np.sum(cond)\n","    else :\n","        if size_feat == None : size = len(freq)\n","#        elif size_feat > len(data) : size = len(freq)\n","        else : size = size_feat\n","    return size\n","\n","def make_encoding_by_freq(freq,null_val='[PAD]',size_feat=None,mode=None):\n","    #빈도수 기반 정수 인코딩 dict 만들기\n","    # freq : token 별 등장 빈도 (value_count), size_feat : size관련 변수(max_size, ths등), mode : size 결정 방법\n","    df_freq = pd.DataFrame(freq).T\n","    df_freq = df_freq.rename(columns={0:'token',1:'counts'})\n","    temp = df_freq.sort_values(by='counts',ascending=False)\n","    size = set_corpus_size(temp,size_feat,mode)\n","    temp = temp.iloc[:size]\n","    temp['val'] = np.arange(size)+1\n","    temp2 = temp.set_index('token').to_dict()\n","    map_token_encode = temp2['val']\n","    map_token_encode[null_val]=0\n","    return map_token_encode\n","\n","def encode_tokens(map_token,x,oov=True):\n","    oov_val = len(map_token)+1 if oov else 0 \n","    return map_token[x] if x in map_token else oov_val\n","\n","def make_author_encode_map(bookinfo,ths_author):\n","    pvtb = pd.pivot_table(data=bookinfo,index='Author',values='SalesPoint',aggfunc=np.sum)\n","    pvtb = pvtb.sort_values(by='SalesPoint',ascending=False)\n","    author_top_k= pvtb[pvtb['SalesPoint']>=ths_author].index\n","    encode_author = pd.DataFrame({'author' : author_top_k.values,'val':np.arange(1,len(author_top_k)+1)})\n","    encode_author = encode_author.set_index('author')\n","    return encode_author.to_dict()['val']\n","\n","def make_publshr_encode_map(publshr_data,ths_publshr):\n","    stats = publshr_data.value_counts().sort_values(ascending=False)\n","    top_k_val = stats.iloc[ths_publshr]\n","    publshr_top_k = list(stats[stats >= top_k_val].index)\n","    return {\n","        publshr : n+1\n","        for n,publshr in enumerate(publshr_top_k)\n","    }\n","    \n","\n","def make_store_encode_map(store_data):\n","    stores= store_data.value_counts().sort_values(ascending=False)\n","    return {\n","        place : n+1\n","        for n,place in enumerate(stores.index)\n","    }"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["file_name = 'bookinfo_ver{}.csv'.format(1.0)\n","file_path = os.path.join(RSLT_DIR,file_name)\n","bookinfo_raw = pd.read_csv(file_path)"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["cols = bookinfo_raw.columns.to_list()\n","x_idxs, y_idx = [0,2,3,4,5,6,9,10], 7\n","x_cols = [cols[i] for i in x_idxs]\n","y_col = cols[y_idx]\n","\n","data_X, data_y  = bookinfo_raw[x_cols], bookinfo_raw[y_col]"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['BName', 'BName_sub', 'Author', 'Publshr', 'Author_mul', 'Pdate',\n","       'SalesPoint', 'Category'],\n","      dtype='object')"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(101173, 8)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(101173,)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(25294, 8)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(25294,)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(31617, 8)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(31617,)"]},"metadata":{},"output_type":"display_data"}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_data, X_tst, y_data, y_tst = train_test_split(data_X,data_y,test_size=0.2,random_state=329)\n","X_trn, X_vld, y_trn, y_vld = train_test_split(X_data,y_data,test_size=0.2,random_state=329)\n","\n","display(X_trn.columns)\n","display(X_trn.shape, y_trn.shape)\n","display(X_vld.shape, y_vld.shape)\n","display(X_tst.shape, y_tst.shape)"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["data_dict = {\n","    'trn': {\n","        'X': X_trn,\n","        'y': y_trn\n","        },\n","    'vld':{\n","        'X': X_vld,\n","        'y': y_vld\n","        },\n","    'tst':{\n","        'X': X_tst,\n","        'y': y_tst\n","        \n","    }\n","}"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 101173 entries, 96986 to 69788\n","Data columns (total 8 columns):\n"," #   Column      Non-Null Count   Dtype \n","---  ------      --------------   ----- \n"," 0   BName       101172 non-null  object\n"," 1   BName_sub   5760 non-null    object\n"," 2   Author      101173 non-null  object\n"," 3   Publshr     101173 non-null  object\n"," 4   Author_mul  101173 non-null  bool  \n"," 5   Pdate       101173 non-null  int64 \n"," 6   SalesPoint  101173 non-null  int64 \n"," 7   Category    101173 non-null  object\n","dtypes: bool(1), int64(2), object(5)\n","memory usage: 6.3+ MB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 25294 entries, 132734 to 43660\n","Data columns (total 8 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   BName       25294 non-null  object\n"," 1   BName_sub   1434 non-null   object\n"," 2   Author      25294 non-null  object\n"," 3   Publshr     25294 non-null  object\n"," 4   Author_mul  25294 non-null  bool  \n"," 5   Pdate       25294 non-null  int64 \n"," 6   SalesPoint  25294 non-null  int64 \n"," 7   Category    25294 non-null  object\n","dtypes: bool(1), int64(2), object(5)\n","memory usage: 1.6+ MB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 31617 entries, 146028 to 115151\n","Data columns (total 8 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   BName       31617 non-null  object\n"," 1   BName_sub   1813 non-null   object\n"," 2   Author      31617 non-null  object\n"," 3   Publshr     31617 non-null  object\n"," 4   Author_mul  31617 non-null  bool  \n"," 5   Pdate       31617 non-null  int64 \n"," 6   SalesPoint  31617 non-null  int64 \n"," 7   Category    31617 non-null  object\n","dtypes: bool(1), int64(2), object(5)\n","memory usage: 2.0+ MB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"}],"source":["display(data_dict['trn']['X'].info())\n","display(data_dict['vld']['X'].info())\n","display(data_dict['tst']['X'].info())"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":["mecab = Mecab()\n","tokenizer_basic = lambda x : mecab.morphs(x)\n","#cut_date = lambda x : [x[:2],x[2:4],x[4:6],x[6:]]\n","#apply tokenizer\n","cols_vec = ['Category','BName','BName_sub']\n","cols_freq = ['Author','Publshr']"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["for mode, data in data_dict.items():\n","    bookinfo = data['X']\n","    for col in cols_vec:\n","        bookinfo[col] = bookinfo[col].fillna('').apply(tokenizer_basic)\n","    #bookinfo['Pdate'] = bookinfo['Pdate'].astype(str).apply(cut_date)\n","    bookinfo[['Author_mul','Pdate']] = bookinfo[['Author_mul','Pdate']].astype(int).astype(str)\n","    data_dict[mode]['X'] = bookinfo"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[],"source":["#아래 ths 는 EDA 결과 제가 자의적으로 정한 내용\n","bookinfo = data_dict['trn']['X']\n","ths_author = int(np.round(len(bookinfo)/500)*75)\n","ths_publshr = int(np.round(len(bookinfo)/500)*5)\n","\n","map_author_encode = make_author_encode_map(bookinfo[['Author','SalesPoint']],ths_author)\n","map_publshr_encode = make_publshr_encode_map(bookinfo['Publshr'],ths_publshr)\n","\n","encode_maps = {\n","    'Author' : lambda x : encode_tokens(map_author_encode,x,oov=False),\n","    'Publshr' : lambda x : encode_tokens(map_publshr_encode,x,oov=False),\n","}"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:00<00:00, 13.18it/s]\n"]}],"source":["for col in tqdm(cols_freq):\n","    bookinfo[col] = bookinfo[col].map(encode_maps[col]).astype(str)"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[],"source":["#make encoding map\n","cols_tknz= ['BName', 'BName_sub', 'Author', 'Publshr', 'Author_mul', 'Pdate','Category']\n","book_tknzed = bookinfo[cols_tknz].to_dict('series')\n","#book_name, book_subname, category = book_tknzed['BName'], book_tknzed['BName_sub'],book_tknzed['Category']"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["array(['19', '92', '37', ..., '392', '0', '0'], dtype=object)"]},"metadata":{},"output_type":"display_data"}],"source":["display('268' in book_tknzed['Publshr'].values)\n","display(book_tknzed['Publshr'].values)"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Author\n","Publshr\n","Author_mul\n","Pdate\n"]}],"source":["cols_num = list(filter(lambda x : x not in cols_vec, cols_tknz))\n","number_slicer = lambda x : [x[max(0,i-2):i] for i in range(len(x),0,-2)[::-1]]\n","for col in cols_num:\n","    print(col)\n","    book_tknzed[col] = book_tknzed[col].apply(number_slicer)"]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[{"data":{"text/plain":["96986        [19]\n","48605        [92]\n","30428        [37]\n","110065       [65]\n","124342    [1, 62]\n","           ...   \n","128584        [1]\n","10037     [1, 68]\n","70829     [3, 92]\n","79290         [0]\n","69788         [0]\n","Name: Publshr, Length: 101173, dtype: object"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["book_tknzed['Publshr']"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[{"data":{"text/plain":["[array(['0', '0', '0', ..., '0', '0', '0'], dtype='<U2'),\n"," array(['19', '92', '37', ..., '92', '0', '0'], dtype='<U2'),\n"," array(['1', '0', '0', ..., '1', '0', '0'], dtype='<U1'),\n"," array(['20', '15', '05', ..., '11', '03', '21'], dtype='<U2'),\n"," array(['소설', '/', '시', ..., '/', '전문', '서적'], dtype='<U3'),\n"," array(['니세코', '이', '비하인드', ..., '원리', '와', '이론'], dtype='<U15'),\n"," array(['(', '전', '작품', ..., '특별', '판', ')'], dtype='<U13')]"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["tkn_vals=[]\n","for col in cols_num:\n","    tkn_vals.append(np.array(list(itertools.chain(*book_tknzed[col].values))))\n","for col in cols_vec:\n","    temp = pd.Series(list(itertools.chain(*book_tknzed[col].values)))\n","    cond = ~(pd.to_numeric(temp,errors='coerce')).isna()\n","    temp[cond] = temp[cond].apply(number_slicer)\n","    temp[~cond] = temp[~cond].apply(lambda x :[x])\n","    tkn_vals.append(np.array(list(itertools.chain(*temp.values))))\n","    \n","    \n","#tokens = np.concatenate(tkn_vals,axis=0)\n","#tokens\n","tkn_vals"]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[],"source":["tokens = np.concatenate(tkn_vals,axis=0)"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[],"source":["tokens_ds = pd.Series(tokens)\n","cond_numeric = ~(pd.to_numeric(tokens_ds,errors='coerce')).isna()\n","\n","tokens_num = tokens[cond_numeric]\n","tokens_str = tokens[~cond_numeric]\n"]},{"cell_type":"code","execution_count":118,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["824863 822353\n","110 31441\n"]}],"source":["print(len(tokens_num),len(tokens_str))\n","print(len(np.unique(tokens_num)),len(np.unique(tokens_str)))"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[{"data":{"text/plain":["array([[     1, 157455],\n","       [     2,   6217],\n","       [     2,  22521],\n","       [     2,  13736],\n","       [     2,  14905],\n","       [     2,  13936],\n","       [     2,  17652],\n","       [     2,  14136],\n","       [     2,  15021],\n","       [     2,  13977],\n","       [     2,  14020],\n","       [     1,  68256],\n","       [     2,  25577],\n","       [     2,  17373],\n","       [     2,  16984],\n","       [     2,   8453],\n","       [     2,   8460],\n","       [     2,  14468],\n","       [     2,   8385],\n","       [     2,   8649],\n","       [     2,   8872],\n","       [     2,  16041],\n","       [     1,  19417],\n","       [     2, 116666],\n","       [     2,   8538],\n","       [     2,   8723],\n","       [     2,   8377],\n","       [     2,   6275],\n","       [     2,   8251],\n","       [     2,   3384],\n","       [     2,   3847],\n","       [     2,   4150],\n","       [     2,   3310],\n","       [     1,  13618],\n","       [     2,   8444],\n","       [     2,   3357],\n","       [     2,   1069],\n","       [     2,   1027],\n","       [     2,   1048],\n","       [     2,    970],\n","       [     2,   1028],\n","       [     2,   1029],\n","       [     2,    875],\n","       [     2,   1036],\n","       [     1,   9540],\n","       [     2,   1014],\n","       [     2,    955],\n","       [     2,    936],\n","       [     2,    899],\n","       [     2,    998],\n","       [     2,    888],\n","       [     2,    909],\n","       [     2,    842],\n","       [     2,    888],\n","       [     2,    816],\n","       [     1,   8100],\n","       [     2,   1011],\n","       [     2,    917],\n","       [     2,    917],\n","       [     2,    874],\n","       [     2,    829],\n","       [     2,    875],\n","       [     2,    748],\n","       [     2,    772],\n","       [     2,    774],\n","       [     2,    783],\n","       [     1,   6514],\n","       [     2,    934],\n","       [     2,    793],\n","       [     2,    783],\n","       [     2,    845],\n","       [     2,    838],\n","       [     2,    941],\n","       [     2,    822],\n","       [     2,    834],\n","       [     2,    779],\n","       [     2,    886],\n","       [     1,   5848],\n","       [     2,    731],\n","       [     2,    803],\n","       [     2,    754],\n","       [     2,    760],\n","       [     2,    834],\n","       [     2,    860],\n","       [     2,    785],\n","       [     2,    725],\n","       [     2,    826],\n","       [     2,    654],\n","       [     1,   5250],\n","       [     2,    784],\n","       [     2,    700],\n","       [     2,    742],\n","       [     2,    682],\n","       [     2,    823],\n","       [     2,    815],\n","       [     2,    838],\n","       [     2,    730],\n","       [     2,    781],\n","       [     2,    873],\n","       [     1,   4747],\n","       [     2,    893],\n","       [     2,    921],\n","       [     2,    914],\n","       [     2,   1049],\n","       [     2,   1027],\n","       [     2,   1212],\n","       [     2,   1216],\n","       [     2,   1558],\n","       [     2,   1800],\n","       [     2,   3141]])"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["temp,cnt = np.unique(tokens_num,return_counts=True)\n","temp2 = np.apply_along_axis(lambda x : [(len(n),cnt[i]) for i,n in enumerate(x)],axis=0,arr=temp)\n","temp2"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[{"data":{"text/plain":["1.0"]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["np.sum(temp2[:,1][temp2[:,0] < 3])/np.sum(cnt)"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["tkns_num = 31000\n","token_freq_str = np.unique(tokens_str,return_counts=True)\n","token_freq_num = np.unique(tokens_num,return_counts=True)\n","map_token_encode_str = make_encoding_by_freq(token_freq_str,size_feat=tkns_num)\n","map_token_encode_num = make_encoding_by_freq(token_freq_num)"]},{"cell_type":"code","execution_count":122,"metadata":{},"outputs":[{"data":{"text/plain":["(array(['0', '00', '01', '02', '03', '04', '05', '06', '07', '08', '09',\n","        '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19',\n","        '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29',\n","        '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39',\n","        '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49',\n","        '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59',\n","        '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69',\n","        '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79',\n","        '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89',\n","        '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99'],\n","       dtype='<U15'),\n"," array([157455,   6217,  22521,  13736,  14905,  13936,  17652,  14136,\n","         15021,  13977,  14020,  68256,  25577,  17373,  16984,   8453,\n","          8460,  14468,   8385,   8649,   8872,  16041,  19417, 116666,\n","          8538,   8723,   8377,   6275,   8251,   3384,   3847,   4150,\n","          3310,  13618,   8444,   3357,   1069,   1027,   1048,    970,\n","          1028,   1029,    875,   1036,   9540,   1014,    955,    936,\n","           899,    998,    888,    909,    842,    888,    816,   8100,\n","          1011,    917,    917,    874,    829,    875,    748,    772,\n","           774,    783,   6514,    934,    793,    783,    845,    838,\n","           941,    822,    834,    779,    886,   5848,    731,    803,\n","           754,    760,    834,    860,    785,    725,    826,    654,\n","          5250,    784,    700,    742,    682,    823,    815,    838,\n","           730,    781,    873,   4747,    893,    921,    914,   1049,\n","          1027,   1212,   1216,   1558,   1800,   3141]))"]},"execution_count":122,"metadata":{},"output_type":"execute_result"}],"source":["token_freq_num"]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[],"source":["map_token_encode_num_placed = dict()\n","for key,val in map_token_encode_num.items():\n","    if key == '[PAD]' : continue\n","    map_token_encode_num_placed[key] = val+tkns_num\n","\n","map_token_encode_total = dict(map_token_encode_str,**map_token_encode_num_placed)"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[],"source":["encode_1line =lambda x: list(map(lambda y : encode_tokens(map_token_encode_total,y),x))"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"data":{"text/plain":["[31098, 31112, 31112, 31112]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[98, 112, 112, 112]"]},"metadata":{},"output_type":"display_data"}],"source":["display(encode_1line(['68','268','2341252345','askdlfjwef']))\n","display(encode_1line_num(['68','268','2341252345','askdlfjwef']))"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[],"source":["maxlens={\n","    'Category' : 5,\n","    'BName' : 27,\n","    'BName_sub' : 23,\n","    'Pdate' : 4,\n","    'Publshr' : 2,\n","    'Author' : 2,\n","    'Author_mul' : 1\n","}\n","x_cols = ['BName', 'BName_sub', 'Author',\n","   'Author_mul', 'Publshr', 'Pdate','Category']\n","\n","book_cols = ['BName', 'BName_sub', 'Author', 'Author_mul', 'Publshr', 'Pdate',\n","       'RglPrice', 'SalesPoint', 'Category']\n","xcols_scalar = list(filter(lambda x : x not in maxlens.keys(),x_cols)) "]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[],"source":["from module_aladin.nlp import erase_space\n","def find_split_num(text):\n","    pat = r'[\\s\\d]+'\n","    mtch_list = list(re.finditer(pat,text))\n","    c,rslt=0,list()\n","    for m in mtch_list:\n","        if c < m.start() : rslt.append((text[c:m.start()],0))\n","        rslt.append((erase_space(text[m.start():m.end()]),1))\n","        c=m.end()\n","    else :\n","        if c < len(text): rslt.append((text[c:len(text)],0))\n","    return rslt\n","\n","\n","def number_splitter(data):\n","    rslt = list()\n","    for txt in data:\n","        temp = find_split_num(txt)\n","        if not temp :rslt.append(temp)\n","        else :\n","            intrmd=list()\n","            for ele in temp:\n","                if ele[1] == 0 : intrmd.append(ele[0])\n","                else : intrmd.extend(number_slicer(ele[0]))\n","            rslt.extend(intrmd)\n","    return rslt        "]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 7/7 [00:06<00:00,  1.03it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.19it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.15it/s]\n","100%|██████████| 3/3 [00:12<00:00,  4.31s/it]\n"]}],"source":["\n","#encode X\n","X_encoded=dict()\n","for mode,sample in tqdm(data_dict.items()):\n","    X_mode = sample['X'].copy()\n","    #padding and encoding\n","    encoded = pd.DataFrame(index=X_mode.index) \n","    for col in tqdm(x_cols):\n","        if col in cols_num:\n","            X_mode[col] = X_mode[col].apply(number_slicer)\n","        if col in cols_vec:\n","            X_mode[col] = X_mode[col].apply(number_splitter)\n","        \n","        padded = pad_sequences(X_mode[col],padding='post',\n","                                   maxlen=maxlens[col],\n","                                   value='[PAD]',dtype=object)\n","        encoded[col] = list(np.apply_along_axis(encode_1line,0,padded))\n","\n","    concat_tknzed =np.apply_along_axis(np.hstack,1,encoded[list(maxlens.keys())].values)\n","    x_scalar = encoded[xcols_scalar].values\n","    X = np.hstack((concat_tknzed,x_scalar))\n","    X_encoded[mode] = X    "]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[{"data":{"text/plain":["BName         [눈, 이, 아닌, 것, 으로, 도, 읽, 은, 기분]\n","BName_sub                                 []\n","Author                                     0\n","Publshr                                  268\n","Author_mul                                 0\n","Pdate                               20171230\n","SalesPoint                               666\n","Category                               [에세이]\n","Name: 114793, dtype: object"]},"execution_count":129,"metadata":{},"output_type":"execute_result"}],"source":["data_dict['trn']['X'].iloc[74310]"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"data":{"text/plain":["array([2.2000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","       4.3100e+02, 1.5000e+01, 1.3470e+03, 9.7000e+01, 6.9000e+01,\n","       7.5000e+01, 9.1000e+01, 1.1000e+01, 1.9320e+03, 0.0000e+00,\n","       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","       3.1002e+04, 3.1023e+04, 3.1009e+04, 3.1027e+04, 3.1006e+04,\n","       3.1098e+04, 3.1001e+04, 0.0000e+00, 3.1001e+04])"]},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":["X_encoded['trn'][74310]"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[{"data":{"text/plain":["('268', True)"]},"execution_count":131,"metadata":{},"output_type":"execute_result"}],"source":["data_dict['trn']['X'].iloc[74310,3], '268' in data_dict['trn']['X']['Publshr'].values"]},{"cell_type":"code","execution_count":132,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'268'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m map_token_encode_num[\u001b[39m'\u001b[39;49m\u001b[39m268\u001b[39;49m\u001b[39m'\u001b[39;49m]\n","\u001b[0;31mKeyError\u001b[0m: '268'"]}],"source":["map_token_encode_num['268']"]},{"cell_type":"code","execution_count":133,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["0"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["0"]},"metadata":{},"output_type":"display_data"}],"source":["display(np.sum(np.isnan(X_encoded['trn'].astype(np.float64))))\n","display(np.sum(np.isnan(X_encoded['vld'].astype(np.float64))))\n","display(np.sum(np.isnan(X_encoded['tst'].astype(np.float64))))"]},{"cell_type":"code","execution_count":134,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["31095\n","31112.0\n","0.0\n"]}],"source":["print(len(np.unique(X_encoded['trn'])))\n","print(np.max(X_encoded['trn']))\n","print(np.min(X_encoded['trn']))"]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[],"source":["X_coded = {\n","    mode : data.astype(np.int32)\n","    for mode, data in X_encoded.items()\n","} "]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[],"source":["sen_token = {\n","    '[sos]':115,\n","    '[eos]':116\n","}\n","\n","map_token_encode_num.update(sen_token)\n","encode_1line_num =lambda x: list(map(lambda y : encode_tokens(map_token_encode_num,y),x))\n","add_sen_tokn = lambda x : '[sos]'+x+['[eos]']"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[],"source":["from collections import defaultdict\n","y_coded = defaultdict(dict)\n","for mode,sample in data_dict.items():\n","    y_coded[mode]['value'] = sample['y'].to_numpy()\n","    temp = sample['y'].astype(str).apply(lambda x : ['[sos]']+number_slicer(x)[::-1]+['[eos]'])\n","    padded = pad_sequences(temp,padding='post',\n","                                   maxlen=7,\n","                                   value='[PAD]',dtype=object)\n","    intrmd = np.apply_along_axis(encode_1line_num,0,padded)\n","    y_coded[mode]['coded'] = intrmd.astype(np.int32)\n","y_coded['info']['decode_map'] = {\n","    v:k\n","    for k,v in map_token_encode_num.items()}\n","y_coded['info']['freq'] = np.unique(y_coded['trn']['coded'],return_counts=True)\n","    "]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[{"data":{"text/plain":["{'value': array([ 6800, 11900, 20000, ..., 14000,  7000, 20000]),\n"," 'coded': array([[115,  34,  98, ...,   0,   0,   0],\n","        [115,  34,  10, ..., 116,   0,   0],\n","        [115,  34,  34, ..., 116,   0,   0],\n","        ...,\n","        [115,  34,  56, ..., 116,   0,   0],\n","        [115,  34, 105, ...,   0,   0,   0],\n","        [115,  34,  34, ..., 116,   0,   0]], dtype=int32)}"]},"execution_count":153,"metadata":{},"output_type":"execute_result"}],"source":["y_coded['trn']"]},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[{"data":{"text/plain":["dict_keys(['decode_map', 'freq'])"]},"execution_count":154,"metadata":{},"output_type":"execute_result"}],"source":["y_coded['info'].keys()"]},{"cell_type":"code","execution_count":155,"metadata":{},"outputs":[{"data":{"text/plain":["(array([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n","         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n","         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n","         40,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n","         54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n","         67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n","         80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n","         93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n","        106, 107, 108, 109, 110, 115, 116], dtype=int32),\n"," array([236795,   9688,  49952,   2824,      2,  11002,    104,     27,\n","            90,    124,      1,      1,    331,      2,     57,    200,\n","             4,      1,   3633,   1106,    274,     23,     12,      2,\n","            19,     28,   7363,     14,     10,    645,    439,    232,\n","            16, 109727,    104,     84,     56,    831,     19,     17,\n","           192,    248,   2301,     40,     32,   1702,     35,     30,\n","            10,    160,     15,     80,     13,     39,   4653,  12351,\n","            38,   1806,      2,   1706,    432,   6664,      1,      1,\n","           145,     13,     15,     66,   5107,   2624,   1890,    176,\n","          1754,   2395,     20,    245,   1629,     23,     13,     15,\n","            13,     30,      9,     11,    680,     19,     38,    206,\n","          1861,      2,      2,     34,   8243,    509,     10,    658,\n","          1993,    833,     11,      9,     54,     23,     18,   5789,\n","            40,     40,      2,     17,    171, 101173, 101173]))"]},"execution_count":155,"metadata":{},"output_type":"execute_result"}],"source":["y_coded['info']['freq']"]},{"cell_type":"code","execution_count":157,"metadata":{},"outputs":[{"data":{"text/plain":["'/home/doeun/code/AI/ESTSOFT2024/workspace/2.project_text/transformer_models/processed/'"]},"execution_count":157,"metadata":{},"output_type":"execute_result"}],"source":["RSLT_DIR"]},{"cell_type":"code","execution_count":156,"metadata":{},"outputs":[],"source":["data_type = 'encodedXy'\n","strat=0\n","ver=2.5\n","dir_path = os.path.join(RSLT_DIR,'model_input')\n","for mode, x_scaled in X_coded.items():\n","    save_pkl(dir_path,'{}.v{}_st-{}_X_{}.pkl'.format(data_type,ver,strat,mode),x_scaled)\n","for mode,data in y_coded.items(): \n","    save_pkl(dir_path,'{}.v{}_st-{}_y_{}.pkl'.format(data_type,ver,strat,mode),data)"]},{"cell_type":"code","execution_count":141,"metadata":{},"outputs":[{"data":{"text/plain":["dict_keys(['decode_map', 'freq'])"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["cand = list(filter(lambda x : 'info' in x ,os.listdir(dir_path)))\n","\n","temp =load_pkl(os.path.join(dir_path,cand[0]))\n","temp.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}
