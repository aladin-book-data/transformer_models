{"cells":[{"cell_type":"markdown","metadata":{"id":"hMv-mcfb1cxL"},"source":["## 요약\n","- 기존 전처리 코드에서는 정수 인코딩한 token들도 scaling을 진행함\n","- transformer에서 embedding model을 사용하려면 정수 값으로 입력 받아야 함\n","- 또한 중고 도서 데이터가 아닌 도서 정보만 사용\n","- 이에 맞게 코드 수정"]},{"cell_type":"code","execution_count":276,"metadata":{"id":"6Rd3woP61cxV"},"outputs":[],"source":["import os, natsort, re\n","from tqdm import tqdm\n","import time, random"]},{"cell_type":"code","execution_count":277,"metadata":{"id":"Jdm14GU9JE1n"},"outputs":[],"source":["from itertools import repeat, chain\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_absolute_percentage_error as mape\n","from sklearn.metrics import mean_squared_error as mse\n","from sklearn.metrics import mean_squared_log_error as msle\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats(\"png2x\")\n","# 테마 설정: \"default\", \"classic\", \"dark_background\", \"fivethirtyeight\", \"seaborn\"\n","mpl.style.use(\"fivethirtyeight\")\n","# 이미지가 레이아웃 안으로 들어오도록 함\n","mpl.rcParams.update({\"figure.constrained_layout.use\": True})\n","mpl.rcParams['axes.unicode_minus'] = False"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"elapsed":122677,"status":"error","timestamp":1721614229201,"user":{"displayName":"이스트캠퍼스","userId":"11631653647711445405"},"user_tz":-540},"id":"vRSxgFv_1eJE","outputId":"de14af6d-3a18-47a0-8d18-a2e8faa2b8af"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive/\u001b[39m\u001b[39m'\u001b[39m, force_remount\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"tOybaY2Uo27a"},"outputs":[],"source":["#cd /content/drive/MyDrive/AI3_prjct2_aladin/"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQwX5d0D2H8a","outputId":"975fee49-7127-4362-c443-3165e8b76dc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/WASSUP-ESTsoft-AI/project/project2/'\n","/home/doeun/code/AI/ESTSOFT2024/workspace/2.project_text/aladin_book_price/research\n"]}],"source":["cd /content/drive/MyDrive/WASSUP-ESTsoft-AI/project/project2/"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"fPd7uoaa1cxU"},"outputs":[],"source":["# 로컬에서\n","\n","plt.rc(\"font\", family = \"D2Coding\")\n","plt.rcParams[\"axes.unicode_minus\"] = False"]},{"cell_type":"code","execution_count":278,"metadata":{"id":"ZFuEjgvk1cxW"},"outputs":[],"source":["PRJCT_PATH = '/home/doeun/code/AI/ESTSOFT2024/workspace/2.project_text/aladin_book_price/'\n","#PRJCT_PATH = '/content/drive/MyDrive/WASSUP-ESTsoft-AI/project/project2/'\n","#PRJCT_PATH = '/content/drive/MyDrive/AI3_prjct2_aladin/aladin_usedbook/'\n","save_dir = 'processed/model_input'\n","dir_path = os.path.join(PRJCT_PATH,save_dir)\n","#dir_path = './'"]},{"cell_type":"code","execution_count":279,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rI20x4AkwggP","outputId":"2e1482eb-d760-46a3-b32c-97cdf2f2b10b"},"outputs":[{"name":"stdout","output_type":"stream","text":["20250211_reg_simulation.ipynb:Zone.Identifier\n","240710_crawling_step0.ipynb\n","240711_crawling_step1.ipynb\n","240711_preprocess_bookinfo.ipynb\n","240715_encoding_usedinfo.ipynb\n","240716_check_bookinfo.ipynb\n","240716_check_bookinfo2.ipynb\n","240716_encoding_bookinfo.ipynb\n","240717_simple_model_for_sample.ipynb\n","240717_split_and_scale.ipynb\n","240718_step0_by_js.ipynb\n","240719_additional_eda.ipynb\n","240719_simple_model_for_cropped.ipynb\n","240721_GridSearch_for_XGB.ipynb\n","240721_experiment_w_XGB.ipynb\n","240721_hyperparameters_XGB.ipynb\n","241023_basic_model.ipynb\n","241023_preprocess_for_pred_rglr.ipynb\n","241024_basic_torch_model.ipynb\n","250112_modulized_test_20480_init_lr_2.12.ipynb\n","250112_modulized_test_20480_init_lr_2.12.ipynb:Zone.Identifier\n","250112_modulized_test_20480_init_lr_analyze2.ipynb\n","250112_modulized_test_20480_init_lr_analyze2.ipynb:Zone.Identifier\n","250112_modulized_test_plot_rslt.ipynb\n","250112_modulized_test_plot_rslt.ipynb:Zone.Identifier\n","250123_modulized_test_20480_init_lr_test_score.ipynb\n","250123_modulized_test_20480_init_lr_test_score.ipynb:Zone.Identifier\n","250211_reg_simulation.ipynb\n","250308_preprocess_for_pred_rglr2.ipynb\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":280,"metadata":{"id":"EKRTD3PdyQsc"},"outputs":[],"source":["import sys\n","sys.path.append(PRJCT_PATH)"]},{"cell_type":"code","execution_count":281,"metadata":{},"outputs":[],"source":["RSLT_DIR = PRJCT_PATH + 'processed/'\n","\n","bookinfo_name = 'bookinfo_ver{}.pkl'.format(0.75)\n","bookinfo_path = os.path.join(RSLT_DIR,bookinfo_name)\n","\n","sys.path.append(PRJCT_PATH)\n","from module_aladin.file_io import load_pkl, save_pkl\n","from module_aladin.data_process import pd_datetime_2_datenum\n","\n","from konlpy.tag import Mecab\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import itertools\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","execution_count":282,"metadata":{},"outputs":[],"source":["def set_corpus_size(freq,size_feat,mode):\n","    # 입력받은 mode와 size_feat에 따라 size 크기 결정\n","    if mode == 'uniform':\n","        cond = freq['counts']>=freq['counts'].iloc[size_feat]\n","        size = np.sum(cond)\n","    elif mode =='ths':\n","        cond = freq[freq['counts'] > size_feat]\n","        size = np.sum(cond)\n","    else :\n","        if size_feat == None : size = len(freq)\n","#        elif size_feat > len(data) : size = len(freq)\n","        else : size = size_feat\n","    return size\n","\n","def make_encoding_by_freq(freq,null_val='[PAD]',size_feat=None,mode=None):\n","    #빈도수 기반 정수 인코딩 dict 만들기\n","    # freq : token 별 등장 빈도 (value_count), size_feat : size관련 변수(max_size, ths등), mode : size 결정 방법\n","    df_freq = pd.DataFrame(freq).T\n","    df_freq = df_freq.rename(columns={0:'token',1:'counts'})\n","    temp = df_freq.sort_values(by='counts',ascending=False)\n","    size = set_corpus_size(temp,size_feat,mode)\n","    temp = temp.iloc[:size]\n","    temp['val'] = np.arange(size)+1\n","    temp2 = temp.set_index('token').to_dict()\n","    map_token_encode = temp2['val']\n","    map_token_encode[null_val]=0\n","    return map_token_encode\n","\n","def encode_tokens(map_token,x,oov=True):\n","    oov_val = len(map_token)+1 if oov else 0 \n","    return map_token[x] if x in map_token else oov_val\n","\n","def make_author_encode_map(bookinfo,ths_author):\n","    pvtb = pd.pivot_table(data=bookinfo,index='Author',values='SalesPoint',aggfunc=np.sum)\n","    pvtb = pvtb.sort_values(by='SalesPoint',ascending=False)\n","    author_top_k= pvtb[pvtb['SalesPoint']>=ths_author].index\n","    encode_author = pd.DataFrame({'author' : author_top_k.values,'val':np.arange(1,len(author_top_k)+1)})\n","    encode_author = encode_author.set_index('author')\n","    return encode_author.to_dict()['val']\n","\n","def make_publshr_encode_map(publshr_data,ths_publshr):\n","    stats = publshr_data.value_counts().sort_values(ascending=False)\n","    top_k_val = stats.iloc[ths_publshr]\n","    publshr_top_k = list(stats[stats >= top_k_val].index)\n","    return {\n","        publshr : n+1\n","        for n,publshr in enumerate(publshr_top_k)\n","    }\n","    \n","\n","def make_store_encode_map(store_data):\n","    stores= store_data.value_counts().sort_values(ascending=False)\n","    return {\n","        place : n+1\n","        for n,place in enumerate(stores.index)\n","    }"]},{"cell_type":"code","execution_count":283,"metadata":{},"outputs":[],"source":["file_name = 'bookinfo_ver{}.csv'.format(1.0)\n","file_path = os.path.join(RSLT_DIR,file_name)\n","bookinfo_raw = pd.read_csv(file_path)"]},{"cell_type":"code","execution_count":284,"metadata":{},"outputs":[],"source":["cols = bookinfo_raw.columns.to_list()\n","x_idxs, y_idx = [0,2,3,4,5,6,9,10], 7\n","x_cols = [cols[i] for i in x_idxs]\n","y_col = cols[y_idx]\n","\n","data_X, data_y  = bookinfo_raw[x_cols], bookinfo_raw[y_col]"]},{"cell_type":"code","execution_count":285,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['BName', 'BName_sub', 'Author', 'Publshr', 'Author_mul', 'Pdate',\n","       'SalesPoint', 'Category'],\n","      dtype='object')"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(101173, 8)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(101173,)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(25294, 8)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(25294,)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(31617, 8)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(31617,)"]},"metadata":{},"output_type":"display_data"}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_data, X_tst, y_data, y_tst = train_test_split(data_X,data_y,test_size=0.2,random_state=329)\n","X_trn, X_vld, y_trn, y_vld = train_test_split(X_data,y_data,test_size=0.2,random_state=329)\n","\n","display(X_trn.columns)\n","display(X_trn.shape, y_trn.shape)\n","display(X_vld.shape, y_vld.shape)\n","display(X_tst.shape, y_tst.shape)"]},{"cell_type":"code","execution_count":286,"metadata":{},"outputs":[],"source":["data_dict = {\n","    'trn': {\n","        'X': X_trn,\n","        'y': y_trn\n","        },\n","    'vld':{\n","        'X': X_vld,\n","        'y': y_vld\n","        },\n","    'tst':{\n","        'X': X_tst,\n","        'y': y_tst\n","        \n","    }\n","}"]},{"cell_type":"code","execution_count":287,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 101173 entries, 96986 to 69788\n","Data columns (total 8 columns):\n"," #   Column      Non-Null Count   Dtype \n","---  ------      --------------   ----- \n"," 0   BName       101172 non-null  object\n"," 1   BName_sub   5760 non-null    object\n"," 2   Author      101173 non-null  object\n"," 3   Publshr     101173 non-null  object\n"," 4   Author_mul  101173 non-null  bool  \n"," 5   Pdate       101173 non-null  int64 \n"," 6   SalesPoint  101173 non-null  int64 \n"," 7   Category    101173 non-null  object\n","dtypes: bool(1), int64(2), object(5)\n","memory usage: 6.3+ MB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 25294 entries, 132734 to 43660\n","Data columns (total 8 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   BName       25294 non-null  object\n"," 1   BName_sub   1434 non-null   object\n"," 2   Author      25294 non-null  object\n"," 3   Publshr     25294 non-null  object\n"," 4   Author_mul  25294 non-null  bool  \n"," 5   Pdate       25294 non-null  int64 \n"," 6   SalesPoint  25294 non-null  int64 \n"," 7   Category    25294 non-null  object\n","dtypes: bool(1), int64(2), object(5)\n","memory usage: 1.6+ MB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 31617 entries, 146028 to 115151\n","Data columns (total 8 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   BName       31617 non-null  object\n"," 1   BName_sub   1813 non-null   object\n"," 2   Author      31617 non-null  object\n"," 3   Publshr     31617 non-null  object\n"," 4   Author_mul  31617 non-null  bool  \n"," 5   Pdate       31617 non-null  int64 \n"," 6   SalesPoint  31617 non-null  int64 \n"," 7   Category    31617 non-null  object\n","dtypes: bool(1), int64(2), object(5)\n","memory usage: 2.0+ MB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"}],"source":["display(data_dict['trn']['X'].info())\n","display(data_dict['vld']['X'].info())\n","display(data_dict['tst']['X'].info())"]},{"cell_type":"code","execution_count":288,"metadata":{},"outputs":[],"source":["mecab = Mecab()\n","tokenizer_basic = lambda x : mecab.morphs(x)\n","cut_date = lambda x : [x[:4],x[4:6],x[6:]]\n","#apply tokenizer\n","cols_tknz = ['Category','BName','BName_sub']\n","cols_freq = ['Author','Publshr']"]},{"cell_type":"code","execution_count":289,"metadata":{},"outputs":[],"source":["for mode, data in data_dict.items():\n","    bookinfo = data['X']\n","    for col in cols_tknz:\n","        bookinfo[col] = bookinfo[col].fillna('').apply(tokenizer_basic)\n","    bookinfo['Pdate'] = bookinfo['Pdate'].astype(str).apply(cut_date)\n","    bookinfo['Author_mul'] = bookinfo['Author_mul'].astype(int).astype(str)\n","    data_dict[mode]['X'] = bookinfo"]},{"cell_type":"code","execution_count":290,"metadata":{},"outputs":[],"source":["#아래 ths 는 EDA 결과 제가 자의적으로 정한 내용\n","bookinfo = data_dict['trn']['X']\n","ths_author = int(np.round(len(bookinfo)/500)*75)\n","ths_publshr = int(np.round(len(bookinfo)/500)*5)\n","\n","map_author_encode = make_author_encode_map(bookinfo[['Author','SalesPoint']],ths_author)\n","map_publshr_encode = make_publshr_encode_map(bookinfo['Publshr'],ths_publshr)\n","\n","encode_maps = {\n","    'Author' : lambda x : encode_tokens(map_author_encode,x,oov=False),\n","    'Publshr' : lambda x : encode_tokens(map_publshr_encode,x,oov=False),\n","}"]},{"cell_type":"code","execution_count":291,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:00<00:00, 14.18it/s]\n"]}],"source":["for col in tqdm(cols_freq):\n","    bookinfo[col] = bookinfo[col].map(encode_maps[col]).astype(str)"]},{"cell_type":"code","execution_count":292,"metadata":{},"outputs":[],"source":["#make encoding map\n","cols_vec = cols_tknz + ['Pdate']\n","cols_tknz2= ['BName', 'BName_sub', 'Author', 'Publshr', 'Author_mul', 'Pdate','Category']\n","book_tknzed = bookinfo[cols_tknz2].to_dict('series')\n","#book_name, book_subname, category = book_tknzed['BName'], book_tknzed['BName_sub'],book_tknzed['Category']"]},{"cell_type":"code","execution_count":293,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["array(['19', '92', '37', ..., '392', '0', '0'], dtype=object)"]},"metadata":{},"output_type":"display_data"}],"source":["display('268' in book_tknzed['Publshr'].values)\n","display(book_tknzed['Publshr'].values)"]},{"cell_type":"code","execution_count":294,"metadata":{},"outputs":[{"data":{"text/plain":["['BName', 'BName_sub', 'Author', 'Publshr', 'Author_mul', 'Pdate', 'Category']"]},"execution_count":294,"metadata":{},"output_type":"execute_result"}],"source":["cols_tknz2"]},{"cell_type":"code","execution_count":295,"metadata":{},"outputs":[{"data":{"text/plain":["[array(['니세코', '이', '비하인드', ..., '원리', '와', '이론'], dtype='<U15'),\n"," array(['(', '전', '작품', ..., '특별', '판', ')'], dtype='<U13'),\n"," array(['0', '0', '0', ..., '0', '0', '0'], dtype='<U4'),\n"," array(['19', '92', '37', ..., '392', '0', '0'], dtype='<U4'),\n"," array(['1', '0', '0', ..., '1', '0', '0'], dtype='<U1'),\n"," array(['2015', '05', '07', ..., '2011', '03', '21'], dtype='<U4'),\n"," array(['소설', '/', '시', ..., '/', '전문', '서적'], dtype='<U3')]"]},"execution_count":295,"metadata":{},"output_type":"execute_result"}],"source":["tkn_vals=[]\n","for col in cols_tknz2:\n","    if col in cols_vec:\n","        tkn_vals.append(np.array(list(itertools.chain(*book_tknzed[col].values))))\n","    else : tkn_vals.append(np.array(list(itertools.chain(book_tknzed[col].values))))\n","#tokens = np.concatenate(tkn_vals,axis=0)\n","#tokens\n","tkn_vals"]},{"cell_type":"code","execution_count":296,"metadata":{},"outputs":[],"source":["tokens = np.concatenate(tkn_vals,axis=0)"]},{"cell_type":"code","execution_count":297,"metadata":{},"outputs":[],"source":["tokens_ds = pd.Series(tokens)\n","cond_numeric = ~(pd.to_numeric(tokens_ds,errors='coerce')).isna()\n","\n","tokens_num = tokens[cond_numeric]\n","tokens_str = tokens[~cond_numeric]\n"]},{"cell_type":"code","execution_count":298,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["657355 822353\n","1769 31441\n"]}],"source":["print(len(tokens_num),len(tokens_str))\n","print(len(np.unique(tokens_num)),len(np.unique(tokens_str)))"]},{"cell_type":"code","execution_count":299,"metadata":{},"outputs":[{"data":{"text/plain":["array([[     1, 157443],\n","       [     2,      9],\n","       [     4,      1],\n","       ...,\n","       [     4,      2],\n","       [     3,     69],\n","       [     4,      3]])"]},"execution_count":299,"metadata":{},"output_type":"execute_result"}],"source":["temp,cnt = np.unique(tokens_num,return_counts=True)\n","temp2 = np.apply_along_axis(lambda x : [(len(n),cnt[i]) for i,n in enumerate(x)],axis=0,arr=temp)\n","temp2"]},{"cell_type":"code","execution_count":300,"metadata":{},"outputs":[{"data":{"text/plain":["0.7452731020529242"]},"execution_count":300,"metadata":{},"output_type":"execute_result"}],"source":["np.sum(temp2[:,1][temp2[:,0] < 3])/np.sum(cnt)"]},{"cell_type":"code","execution_count":305,"metadata":{},"outputs":[],"source":["tkns_num = 31000\n","token_freq_str = np.unique(tokens_str,return_counts=True)\n","token_freq_num = np.unique(tokens_num,return_counts=True)\n","map_token_encode_str = make_encoding_by_freq(token_freq_str,size_feat=tkns_num)\n","map_token_encode_num = make_encoding_by_freq(token_freq_num)"]},{"cell_type":"code","execution_count":306,"metadata":{},"outputs":[],"source":["for key,val in map_token_encode_num.items():\n","    if key == '[PAD]' : continue\n","    map_token_encode_num[key] = val+tkns_num\n","\n","map_token_encode_total = dict(map_token_encode_str,**map_token_encode_num)"]},{"cell_type":"code","execution_count":307,"metadata":{},"outputs":[],"source":["encode_1line =lambda x: list(map(lambda y : encode_tokens(map_token_encode_total,y),x))"]},{"cell_type":"code","execution_count":308,"metadata":{},"outputs":[{"data":{"text/plain":["[31375, 32771, 32771]"]},"execution_count":308,"metadata":{},"output_type":"execute_result"}],"source":["encode_1line(['268','2341252345','askdlfjwef'])"]},{"cell_type":"code","execution_count":309,"metadata":{},"outputs":[],"source":["maxlens={\n","    'Category' : 5,\n","    'BName' : 28,\n","    'BName_sub' : 25,\n","    'Pdate':3\n","}\n","x_cols = ['BName', 'BName_sub', 'Author',\n","   'Author_mul', 'Publshr', 'Pdate','Category']\n","\n","book_cols = ['BName', 'BName_sub', 'Author', 'Author_mul', 'Publshr', 'Pdate',\n","       'RglPrice', 'SalesPoint', 'Category']\n","xcols_scalar = list(filter(lambda x : x not in maxlens.keys(),x_cols)) "]},{"cell_type":"code","execution_count":310,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:08<00:00,  2.87s/it]\n"]}],"source":["#encode X\n","X_encoded=dict()\n","for mode,sample in tqdm(data_dict.items()):\n","    X_mode = sample['X']\n","    #padding and encoding\n","    encoded = pd.DataFrame(index=X_mode.index) \n","    for col in x_cols:\n","        if col in maxlens:\n","            padded = pad_sequences(X_mode[col],padding='post',\n","                                   maxlen=maxlens[col],\n","                                   value='[PAD]',dtype=object)\n","            encoded[col] = list(np.apply_along_axis(encode_1line,0,padded))\n","        else :\n","            encoded[col] = encode_1line(X_mode[col].values)\n","\n","    concat_tknzed =np.apply_along_axis(np.hstack,1,encoded[list(maxlens.keys())].values)\n","    x_scalar = encoded[xcols_scalar].values\n","    X = np.hstack((concat_tknzed,x_scalar))\n","    X_encoded[mode] = X    "]},{"cell_type":"code","execution_count":311,"metadata":{},"outputs":[{"data":{"text/plain":["BName         [눈, 이, 아닌, 것, 으로, 도, 읽, 은, 기분]\n","BName_sub                                 []\n","Author                                     0\n","Publshr                                  268\n","Author_mul                                 0\n","Pdate                         [2017, 12, 30]\n","SalesPoint                               666\n","Category                               [에세이]\n","Name: 114793, dtype: object"]},"execution_count":311,"metadata":{},"output_type":"execute_result"}],"source":["data_dict['trn']['X'].iloc[74310]"]},{"cell_type":"code","execution_count":312,"metadata":{},"outputs":[{"data":{"text/plain":["('268', True)"]},"execution_count":312,"metadata":{},"output_type":"execute_result"}],"source":["data_dict['trn']['X'].iloc[74310,3], '268' in data_dict['trn']['X']['Publshr'].values"]},{"cell_type":"code","execution_count":313,"metadata":{},"outputs":[{"data":{"text/plain":["31375"]},"execution_count":313,"metadata":{},"output_type":"execute_result"}],"source":["map_token_encode_num['268']"]},{"cell_type":"code","execution_count":314,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["0"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["0"]},"metadata":{},"output_type":"display_data"}],"source":["display(np.sum(np.isnan(X_encoded['trn'].astype(np.float64))))\n","display(np.sum(np.isnan(X_encoded['vld'].astype(np.float64))))\n","display(np.sum(np.isnan(X_encoded['tst'].astype(np.float64))))"]},{"cell_type":"code","execution_count":315,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["32759\n","32771\n","0\n"]}],"source":["print(len(np.unique(X_encoded['trn'])))\n","print(np.max(X_encoded['trn']))\n","print(np.min(X_encoded['trn']))"]},{"cell_type":"code","execution_count":242,"metadata":{},"outputs":[],"source":["X_coded = {\n","    mode : data.astype(np.int32)\n","    for mode, data in X_encoded.items()\n","} "]},{"cell_type":"code","execution_count":245,"metadata":{},"outputs":[],"source":["data_type = 'whole-encoded'\n","strat=0\n","ver=1.0\n","dir_path = os.path.join(RSLT_DIR,'model_input')\n","for mode, x_scaled in X_coded.items():\n","    save_pkl(dir_path,'{}.v{}_st-{}_X_{}.pkl'.format(data_type,ver,strat,mode),x_scaled)\n","for mode,sample in data_dict.items(): \n","    save_pkl(dir_path,'{}.v{}_st-{}_y_{}.pkl'.format(data_type,ver,strat,mode),sample['y'].to_numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}
